ğŸ¶ Emotion-Based Music Player ğŸ¶
Welcome to the Emotion-Based Music Player, a fun, interactive, and smart music player that reads your emotions and adapts accordingly! ğŸ˜„ğŸ˜ŒğŸ˜¡ğŸ˜¢

Built for TOHacks 2021, this web app utilizes cutting-edge machine learning algorithms to detect your mood through facial recognition, then recommends a custom playlist and changes the background theme based on your emotion! ğŸ§ ğŸ’»ğŸ§

ğŸš€ Getting Started:
Ready to get the app running on your local machine? Follow these simple steps:

Clone this repository:

bash
Copy
Edit
git clone https://github.com/your-username/emotion-music-player.git
cd emotion-music-player
Install dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Run the server:

bash
Copy
Edit
python manage.py runserver
ğŸ”§ Prerequisites:
Check out the required dependencies in requirements.txt to ensure the app runs smoothly. Some of the key libraries used are:

tensorflow-cpu: For training and using the emotion detection model ğŸ§ 

opencv-python-headless: Used for facial recognition ğŸ‘€

Django: Backend framework for smooth integration ğŸ–¥ï¸

gunicorn: For hosting the app on Heroku âš™ï¸

ğŸŒ Deployed App:
Experience the magic right now! The web app is already deployed on Heroku:

Live Demo - Emotion-Based Music Player ğŸ§

ğŸ’¡ How It Works:
Using a Haar Cascade face detection model ğŸ§‘â€ğŸ’», combined with a CNN classifier trained on TensorFlow ğŸ“Š, the app detects four key emotionsâ€”Angry, Happy, Calm, and Sadâ€”from your facial expression. The app then dynamically changes the music playlist and background according to your mood! ğŸ¶

ğŸ”¬ Built With:
HTML/CSS: For creating the attractive front-end design ğŸ’…

JavaScript: To handle the interactive music player functionality ğŸµ

Django: Backend integration to power the emotion-based logic ğŸ”„

OpenCV: Face detection for emotion recognition ğŸ“¸

TensorFlow: For training the emotion classifier ğŸ”

ğŸ“Š Training the Model:
The emotion detection model was trained using a dataset from the Kaggle Facial Expression Recognition Challenge. The dataset consists of 48x48 grayscale images of faces, and we used the four most common emotional expressions: Angry, Happy, Calm, and Sad. ğŸ¤–ğŸ’“

Final Accuracy: 58.33%
Validation Accuracy: 54.99%

ğŸ“ Dataset:
You can access the dataset used to train the model from Kaggle's Facial Expression Recognition Challenge. A direct link to the dataset can be found here.

ğŸŒŸ Contribute:
Feel free to fork this repository and create a pull request if you have any suggestions or improvements. Let's make music and emotions even more fun! ğŸ‰ğŸ¶

Enjoy your personalized music experience! ğŸ˜ğŸ§
